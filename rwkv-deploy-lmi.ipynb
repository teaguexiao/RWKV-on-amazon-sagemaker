{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d443515c-8e27-4ac8-937d-afed9158fda5",
   "metadata": {},
   "source": [
    "# Deploy RWKV Hugging Face models to Amazon SageMaker by using LMI, DeepSpeed \n",
    "\n",
    "reference:\n",
    "\n",
    "https://huggingface.co/RWKV\n",
    "\n",
    "https://sagemaker.readthedocs.io/en/stable/frameworks/djl/using_djl.html\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/large-model-inference-dlc.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c77563-71e1-4319-8fc8-c11867cc6a72",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "224e561c-2076-4408-8fb4-d90cf512dade",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#upgrade sdk library\n",
    "!pip install -qU sagemaker\n",
    "!pip install -qU boto3\n",
    "!pip install -qU botocore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "005ed1be-985e-445c-9eee-e8fa1aecd71d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::432088571089:role/AmazonSageMaker-ExecutionRole-20210324T123126\n",
      "sagemaker bucket: sagemaker-us-east-1-432088571089\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "# sagemaker environment setting\n",
    "import sagemaker\n",
    "import boto3\n",
    "import os\n",
    "import shutil\n",
    "import sagemaker.huggingface\n",
    "from sagemaker.djl_inference.model import DJLModel,DeepSpeedModel,HuggingFaceAccelerateModel,DJLPredictor\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sagemaker_session is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sagemaker_session = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {bucket}\")\n",
    "print(f\"sagemaker session region: {region}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "200f0932-55e5-4b1c-8ece-33b62b6d6bdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "source_dir = 'source_dir'\n",
    "if not os.path.exists(source_dir):\n",
    "    os.mkdir(source_dir)\n",
    "#entry_point = 'entry_point.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237b0513-0fdc-4339-b742-051e38529020",
   "metadata": {},
   "source": [
    "### NOTE: From v4.29.0, RWKV was supported by Transformers, the built-in Transformers(4.26.0) needs to be upgraded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de0e97a5-5eb4-48f4-ada3-5e04cbea6d5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting source_dir/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile $source_dir/requirements.txt\n",
    "transformers==4.30.2\n",
    "boto3\n",
    "sagemaker\n",
    "sentencepiece\n",
    "nvgpu==0.9.0\n",
    "pynvml==11.4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5023bede-838e-40df-922c-b917268d2660",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Download model files from Hugging Face Hub, then upload them to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1a49197-8750-4503-9fa6-e13e27cceb34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 4176k  100 4176k    0     0  21.5M      0 --:--:-- --:--:-- --:--:-- 21.5M\n"
     ]
    }
   ],
   "source": [
    "!curl -L https://github.com/peak/s5cmd/releases/download/v2.0.0/s5cmd_2.0.0_Linux-64bit.tar.gz | tar -xz\n",
    "#!mv s5cmd ./$source_dir/s5cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fcefd54-e2fb-4831-93fb-fb714ed7cefe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"RWKV/rwkv-raven-3b\"#\"RWKV/rwkv-raven-14b\"#\"RWKV/rwkv-4-169m-pile\"#\"RWKV/rwkv-raven-7b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a06d1fb-2c79-4ed7-bf08-7e56f64d348d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -qU huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47edb461-2e52-452a-8ff5-9301afdf60cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5010034f82034b7583a66b8fc37075be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a3ecebeb0e4e1cb5249967abe5ed0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "882cd2e5687a4e349bf1fb892d62d2bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)49458f67/config.json:   0%|          | 0.00/523 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "434cbdffef064cb6a60f7d0271c5cfc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)model.bin.index.json:   0%|          | 0.00/46.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83533ea7e14d427fb10ad5a5442f15df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8610e62515b641ec88c813a6813b24fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)58f67/tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7345563617b0401e953feefac4686cec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00003-of-00007.bin:   0%|          | 0.00/1.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e08a131d4f422c8f02224df3b92602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00002-of-00007.bin:   0%|          | 0.00/1.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "720d0cfd0deb42de8e19c6b28a381911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00001-of-00007.bin:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b49ab30986a4e0697eea86728e62c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/264 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ede8ebe861254ff4adecc96b2e9cf4a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00006-of-00007.bin:   0%|          | 0.00/1.60G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc7a57dde38d43888db1b683ab412438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00005-of-00007.bin:   0%|          | 0.00/1.91G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10e0d6acb534e9cb45b500c8f5a5f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00007-of-00007.bin:   0%|          | 0.00/515M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "448be3848a124fb3b52b6052d2cf0289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00004-of-00007.bin:   0%|          | 0.00/1.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp model/models--RWKV--rwkv-raven-3b/snapshots/1ddeea6a7313c8ba8824645d7aa88d5449458f67/generation_config.json s3://internal-modelzoo-us-east-1/RWKV/rwkv-raven-3b/generation_config.json\n",
      "cp model/models--RWKV--rwkv-raven-3b/snapshots/1ddeea6a7313c8ba8824645d7aa88d5449458f67/config.json s3://internal-modelzoo-us-east-1/RWKV/rwkv-raven-3b/config.json\n",
      "cp model/models--RWKV--rwkv-raven-3b/snapshots/1ddeea6a7313c8ba8824645d7aa88d5449458f67/special_tokens_map.json s3://internal-modelzoo-us-east-1/RWKV/rwkv-raven-3b/special_tokens_map.json\n",
      "cp model/models--RWKV--rwkv-raven-3b/snapshots/1ddeea6a7313c8ba8824645d7aa88d5449458f67/tokenizer.json s3://internal-modelzoo-us-east-1/RWKV/rwkv-raven-3b/tokenizer.json\n",
      "cp model/models--RWKV--rwkv-raven-3b/snapshots/1ddeea6a7313c8ba8824645d7aa88d5449458f67/tokenizer_config.json s3://internal-modelzoo-us-east-1/RWKV/rwkv-raven-3b/tokenizer_config.json\n",
      "cp model/models--RWKV--rwkv-raven-3b/snapshots/1ddeea6a7313c8ba8824645d7aa88d5449458f67/pytorch_model.bin.index.json s3://internal-modelzoo-us-east-1/RWKV/rwkv-raven-3b/pytorch_model.bin.index.json\n",
      "cp model/models--RWKV--rwkv-raven-3b/snapshots/1ddeea6a7313c8ba8824645d7aa88d5449458f67/pytorch_model-00007-of-00007.bin s3://internal-modelzoo-us-east-1/RWKV/rwkv-raven-3b/pytorch_model-00007-of-00007.bin\n",
      "cp model/models--RWKV--rwkv-raven-3b/snapshots/1ddeea6a7313c8ba8824645d7aa88d5449458f67/pytorch_model-00005-of-00007.bin s3://internal-modelzoo-us-east-1/RWKV/rwkv-raven-3b/pytorch_model-00005-of-00007.bin\n",
      "cp model/models--RWKV--rwkv-raven-3b/snapshots/1ddeea6a7313c8ba8824645d7aa88d5449458f67/pytorch_model-00004-of-00007.bin s3://internal-modelzoo-us-east-1/RWKV/rwkv-raven-3b/pytorch_model-00004-of-00007.bin\n",
      "cp model/models--RWKV--rwkv-raven-3b/snapshots/1ddeea6a7313c8ba8824645d7aa88d5449458f67/pytorch_model-00002-of-00007.bin s3://internal-modelzoo-us-east-1/RWKV/rwkv-raven-3b/pytorch_model-00002-of-00007.bin\n",
      "cp model/models--RWKV--rwkv-raven-3b/snapshots/1ddeea6a7313c8ba8824645d7aa88d5449458f67/pytorch_model-00003-of-00007.bin s3://internal-modelzoo-us-east-1/RWKV/rwkv-raven-3b/pytorch_model-00003-of-00007.bin\n",
      "cp model/models--RWKV--rwkv-raven-3b/snapshots/1ddeea6a7313c8ba8824645d7aa88d5449458f67/pytorch_model-00006-of-00007.bin s3://internal-modelzoo-us-east-1/RWKV/rwkv-raven-3b/pytorch_model-00006-of-00007.bin\n",
      "cp model/models--RWKV--rwkv-raven-3b/snapshots/1ddeea6a7313c8ba8824645d7aa88d5449458f67/pytorch_model-00001-of-00007.bin s3://internal-modelzoo-us-east-1/RWKV/rwkv-raven-3b/pytorch_model-00001-of-00007.bin\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "\n",
    "local_model_path = Path(\"./model\")\n",
    "local_model_path.mkdir(exist_ok=True)\n",
    "# Only download pytorch checkpoint files\n",
    "allow_patterns = [\"*.json\", \"*.pt\", \"*.bin\", \"*.txt\", \"*.model\"]\n",
    "# - Leverage the snapshot library to download the model since the model is stored in repository using LFS\n",
    "model_download_path = snapshot_download(\n",
    "    repo_id=model_id,\n",
    "    cache_dir=local_model_path,\n",
    "    allow_patterns=allow_patterns,\n",
    ")\n",
    "\n",
    "# define a variable to contain the s3url of the location that has the model\n",
    "#stabilityai--stable-diffusion-2-1\n",
    "pretrained_model_location = f\"s3://internal-modelzoo-us-east-1/RWKV/{model_id.split('/')[1]}/\"\n",
    "\n",
    "#model_artifact = sess.upload_data(path=model_download_path, key_prefix=s3_model_prefix)\n",
    "!chmod +x ./s5cmd\n",
    "!./s5cmd sync {model_download_path}/ {pretrained_model_location}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1849cd48-e1cf-4db8-8da8-c49e35801392",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model/models--RWKV--rwkv-raven-3b/snapshots/1ddeea6a7313c8ba8824645d7aa88d5449458f67\n",
      "s3://internal-modelzoo-us-east-1/RWKV/rwkv-raven-3b/\n"
     ]
    }
   ],
   "source": [
    "print(model_download_path)\n",
    "print(pretrained_model_location)\n",
    "#!./s5cmd sync {model_download_path}/  {pretrained_model_location}\n",
    "!rm -fr {local_model_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6386a49-c18e-427b-908a-6c9442b370dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LMI + Create a model using the DeepSpeed backend, then do inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca797b94-a274-435c-b6cb-efcfaaedd053",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id:s3://internal-modelzoo-us-east-1/RWKV/rwkv-raven-3b/\n",
      "Deploying..., please wait for 3-10 minutes!\n",
      "-------------!\n",
      "endpoint_name:djl-inference-2023-08-10-06-10-14-302\n"
     ]
    }
   ],
   "source": [
    "# LMI + Create a model using the DeepSpeed backend\n",
    "model_id = \"s3://internal-modelzoo-us-east-1/RWKV/rwkv-raven-3b/\"\n",
    "print(f\"model_id:{model_id}\")\n",
    "\n",
    "deepspeed_model = DeepSpeedModel(\n",
    "    model_id, # This can also be a HuggingFace Hub model id\n",
    "    role,\n",
    "    dtype=\"fp16\",\n",
    "    task=\"text-generation\",\n",
    "    tensor_parallel_degree=1, # number of gpus to partition the model across using tensor parallelism\n",
    "    #entry_point = entry_point,\n",
    "    source_dir = source_dir,\n",
    ")\n",
    "\n",
    "# Deploy the model to an Amazon SageMaker Endpoint and get a Predictor\n",
    "print(f\"Deploying..., please wait for 3-10 minutes!\")\n",
    "deepspeed_predictor = deepspeed_model.deploy(\n",
    "    \"ml.g5.2xlarge\",\n",
    "    initial_instance_count=1,\n",
    "    model_data_download_timeout=10*60,\n",
    "    container_startup_health_check_timeout=15*60\n",
    ")\n",
    "endpoint_name = deepspeed_predictor.endpoint_name\n",
    "print(\"\")\n",
    "print(f\"endpoint_name:{endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b0146ed-0100-4ecd-8cb3-477d950dbba0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'American election is a very important event. It is a chance for the people of the United States to have a say in who will be the next president. It is a chance for the people of the United States to have a say in who will be'}]\n"
     ]
    }
   ],
   "source": [
    "#predict\n",
    "print(deepspeed_predictor.predict(\n",
    "    { \n",
    "        \"inputs\" : \"American election is\", \n",
    "        \"parameters\": { \"max_length\": 50 },\n",
    "    }\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0e6ae81-8ed1-424f-882d-b6ad15daf227",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id:s3://internal-modelzoo-us-east-1/RWKV/rwkv-raven-3b/\n",
      "Deploying..., please wait for 3-10 minutes!\n",
      "------------![{'generated_text': 'Large model inference is a challenging task due to the high dimensionality of the model and the large number of parameters. In this paper, we propose a novel approach to model inference that leverages the power of deep learning. Our approach is based on the'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # LMI + Create a model using the HuggingFace Accelerate backend\n",
    "# model_id = \"s3://internal-modelzoo-us-east-1/RWKV/rwkv-raven-3b/\"\n",
    "# print(f\"model_id:{model_id}\")\n",
    "\n",
    "# hf_accelerate_model = HuggingFaceAccelerateModel(\n",
    "#     model_id, # This can also be a HuggingFace Hub model id\n",
    "#     role,\n",
    "#     dtype=\"fp16\",\n",
    "#     task=\"text-generation\",\n",
    "#     number_of_partitions=1, # number of gpus to partition the model across\n",
    "#     #entry_point = entry_point,\n",
    "#     source_dir = source_dir\n",
    "# )\n",
    "# # Deploy the model to an Amazon SageMaker Endpoint and get a Predictor\n",
    "# print(f\"Deploying..., please wait for 3-10 minutes!\")\n",
    "\n",
    "# hf_accelerate_predictor = hf_accelerate_model.deploy(\"ml.g5.2xlarge\",\n",
    "#                                                      initial_instance_count=1,\n",
    "#                                                      model_data_download_timeout=10*60,\n",
    "#                                                      container_startup_health_check_timeout=15*60)\n",
    "# #predict\n",
    "# print(hf_accelerate_predictor.predict(\n",
    "#     { \n",
    "#         \"inputs\" : \"Large model inference is\", \n",
    "#         \"parameters\": { \"max_length\": 50 },\n",
    "#     }\n",
    "# ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ffdb84-8f17-43ca-b5fe-348d01a27de8",
   "metadata": {},
   "source": [
    "## ONLY for re-invoke already-created endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab252a6b-e7a4-4253-8281-85deff803b2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Today is sunny, but the wind is blowing hard.\\n\\nBob: Can you tell me more about the weather forecast for tomorrow?\\n\\nAlice: Sure, I can provide you with the weather forecast for tomorrow. The weather is expected to'}]\n"
     ]
    }
   ],
   "source": [
    "#only for re-invoke already-created endpoint\n",
    "endpoint_name=\"djl-inference-2023-06-18-14-37-50-264\"\n",
    "endpoint_name=\"djl-inference-2023-08-10-06-10-14-302\"\n",
    "from sagemaker.djl_inference.model import DJLPredictor\n",
    "from sagemaker import Model, image_uris, serializers, deserializers\n",
    "\n",
    "predictor = DJLPredictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    serializer=serializers.JSONSerializer(),\n",
    "    deserializer=deserializers.JSONDeserializer(),\n",
    ")\n",
    "#predict\n",
    "print(predictor.predict(\n",
    "    { \n",
    "        \"inputs\" : \"Today is sunny,\", \n",
    "        \"parameters\": { \"max_length\": 50 },\n",
    "    }\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0176edd-0a56-4756-ba05-698db2464447",
   "metadata": {},
   "source": [
    "## clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85351ea4-e0e0-4194-b07c-605f243abd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#endpoint_name = \"\"\n",
    "#model_name = \"\"\n",
    "#sagemaker_session.delete_endpoint(endpoint_name)\n",
    "#sagemaker_session.delete_endpoint_config(endpoint_name)\n",
    "#sagemaker_session.delete_model(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc254fc-0506-4d29-9990-4a2f33a942b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
